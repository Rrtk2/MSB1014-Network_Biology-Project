queryResultsBACKUP = queryResults
# Finalize data structure
queryResults = data.frame(queryResultsBACKUP$compLabel, queryResultsBACKUP$bp, queryResultsBACKUP$CC)
names(queryResults) = c("Comp","bp","CC")
#-----------------------------------------------------------------------------------------------------#
#		Block 03		FILTERS AND OUTLIER HANDLING
#-----------------------------------------------------------------------------------------------------#
if(linearAlkanesOnly == 1){
queryResults = queryResults[-grep(pattern = "\\(",x = queryResults$CC),]
}
# hexatriacontane 770.15 K (497 C); in wikidata under pressurised condition!
if(!length(queryResults$Comp=="hexatriacontane")==0){
queryResults$bp[queryResults$Comp=="hexatriacontane"] = 770.15
}
# Dooctacontane 958.05 K (684.9 C); IN WIKIDATA AS 881.85 K
if(!length(queryResults$Comp=="Dooctacontane")==0){
queryResults$bp[queryResults$Comp=="Dooctacontane"] = 958.05
}
# phytane 612.32 K (322.4 C); IN WIKIDATA AS 442.65 K at 760 torr which should be (322.4 C) 612.32 K.
if(!length(queryResults$Comp=="phytane")==0){
queryResults$bp[queryResults$Comp=="phytane"] = 612.32
}
#-----------------------------------------------------------------------------------------------------#
#		Block 03		DATA VIZ
#-----------------------------------------------------------------------------------------------------#
# Get a general idea of how the data looks; disregarding branch effects; amount of C in compound linked to BP
CClength_crude = nchar(gsub(pattern = "\\)",replacement = "",x = gsub(pattern = "\\(",replacement = "",x = queryResults$CC)))
plotCClength = CClength_crude[order(CClength_crude)]
plotBP = queryResults$bp[order(CClength_crude)]
# Should result in a exponential function-like graph
plot(plotCClength,plotBP,main = "Carbon - boilingpoint relation",xlab = "Amount of carbon atoms in alkene",ylab = "Boiling point (Kelvin)")
# Show how the data is distributed (focussing on bp)
hist(queryResults$bp,breaks=20,main = "Boiling point frequency distribution",xlab = "Boiling point (Kelvin)",ylab = "Frequency")
#-----------------------------------------------------------------------------------------------------#
# 		Block 03		rcdk data extraction see:https://cran.r-project.org/web/packages/rcdk/vignettes/molform.html
#-----------------------------------------------------------------------------------------------------#
smilesParser <- get.smiles.parser()
descCategories <- get.desc.categories()
for( i in 1:length(queryResults$CC)){
# Get smiles from result query and add information
selectedSmilesData <- parse.smiles(queryResults$CC[i])[[1]]
convert.implicit.to.explicit(selectedSmilesData)
#formula <- get.mol2formula(selectedSmilesData,charge=0)
# Store the found information
#queryResults$formula[i] = {formula} # S4 object cannot be transferred nicely
#queryResults$mass[i] = formula@mass
#queryResults$string[i] = formula@string
#queryResults$charge[i] = formula@charge
# M/z values
#queryResults$isotopes[i] = {get.isotopes.pattern(formula,minAbund=0.1)}
# Fingerprint? values
#queryResults$fingerprint[i] = {get.fingerprint(selectedSmilesData = selectedSmilesData)}
# Create a dataframe which contains all info possible to extract using the descriptors
rowSmileDescData = queryResults$Comp[i]
for(o in 1:5){
dn <- get.desc.names(descCategories[o])
rowSmileDescData = cbind(rowSmileDescData, eval.desc(selectedSmilesData, dn))
}
# This is done now as it will break if descriptors change (amount)
if(exists("dfSmilesDescData")){
dfSmilesDescData[i,] = rowSmileDescData
}else{
dfSmilesDescData = rowSmileDescData
}
}
# Make backup from data, easy for testing (resetting)
mydataBACKUP = dfSmilesDescData
dfSmilesDescData = mydataBACKUP
# Remove component names (as it will mess up futher processing)
dfSmilesDescData = dfSmilesDescData[,-1]
#-----------------------------------------------------------------------------------------------------#
#							Latent variable selection (correlation)
#-----------------------------------------------------------------------------------------------------#
# Remove NAs n stuff
dfSmilesDescData <- dfSmilesDescData[, !apply(dfSmilesDescData, 2, function(x) any(is.na(x)) )]
dfSmilesDescData <- dfSmilesDescData[, !apply( dfSmilesDescData, 2, function(x) length(unique(x)) == 1 )]
if(T){
# Correlate the descriptors with the boiling point; if these are linked, they should add some info
corMatrix = cor(dfSmilesDescData , queryResults$bp)
corMatrix = as.data.frame(corMatrix[order(abs(corMatrix),decreasing = T),])
# select first 15 components:
componentNames = rownames(corMatrix)[1:15]
dfSmilesDescData = dfSmilesDescData[,match(colnames(dfSmilesDescData), x = componentNames)]
}
# - BLOCKED - Old method, keepin this inside for further reference
if(F){
dfSmilesDescData = mydataBACKUP
dfSmilesDescData = dfSmilesDescData[,-1]
# crude way to extract 'important' features based on correlation
dfSmilesDescData <- dfSmilesDescData[, !apply(dfSmilesDescData, 2, function(x) any(is.na(x)) )]
dfSmilesDescData <- dfSmilesDescData[, !apply( dfSmilesDescData, 2, function(x) length(unique(x)) == 1 )]
r2 <- which(cor(dfSmilesDescData)^2 > .9, arr.ind=TRUE) # when keeping this high, the prediction improves
r2 <- r2[ r2[,1] > r2[,2] , ]
dfSmilesDescData <- dfSmilesDescData[, -unique(r2[,2])]
}
# - BLOCKED -
# should contain nAtomLAC; the amount of c atoms
if(!exists("dfSmilesDescData$nAtomLAC")){
dfSmilesDescData = cbind(dfSmilesDescData, dfSmilesDescData$nAtomLAC)
names(dfSmilesDescData)[dim(dfSmilesDescData)[2]] = "n"
}else{
names(dfSmilesDescData)[names(dfSmilesDescData)=="dfSmilesDescData$nAtomLAC"] = "n"
}
# Store resulting input file in dfInputML; as it is the input for ML
dfInputML = dfSmilesDescData
# Finish prepare data
# Add and define the 'to be predicted' column
indexBoilPoint = ncol(dfInputML)+1
dfInputML[,indexBoilPoint] = queryResults$bp
names(dfInputML)[indexBoilPoint] = 'BoilPoint'
# Ordered data is required later
dfInputML = dfInputML[order(dfInputML$BoilPoint),]
#-----------------------------------------------------------------------------------------------------#
#							MACHINE LEARNING
#-----------------------------------------------------------------------------------------------------#
#-----------------------------------------------------------------------------------------------------#
# 				Data subsetting; Train; Test
#-----------------------------------------------------------------------------------------------------#
# Define variables
sample.length = length(dfInputML[,1])
# Higher probability to select lower (underrepresented) samples;
# improves range of model, increases fit and prediction power.
# Ranges from 1 (select) to 0.5 (chance)
sample.biasprob = 1 - 1:sample.length /max(sample.length )/2
# Make data objects
samples.upper = sample(sample.length , floor(length(dfInputML[,1])*trainingTestRatio),prob = sample.biasprob ) #get all unique samples (not frequecies) and sample 80%
#plot(samples.upper[order(samples.upper)])
samples.total = (1:length(dfInputML[,1])) # all unique samples (not frequecies)
samples.lowerl = samples.total[!samples.total %in% samples.upper]  #which samples are sampled
# Subset data
data.train = dfInputML[samples.upper,]#contains all upper
data.train = as.data.frame(data.train)
data.test = dfInputML[samples.lowerl,]#contains all lower
data.test = as.data.frame(data.test)
# Remove nas
data.train=data.train[!is.na(data.train[,1]),]
data.test=data.test[!is.na(data.test[,1]),]
# Create standardized object
xNN = data.train[,-(indexBoilPoint)]
yNN = data.train[,indexBoilPoint]
dat = data.frame(xNN, y = yNN)
# Remove samples with in datasets n < 1
data.train = dat[dat$n>0,]
yactual.train = data.train$y
data.test = data.test[data.test$n>0,]
yactual.test = data.test$BoilPoint
#-----------------------------------------------------------------------------------------------------#
#							CARET : pls
#-----------------------------------------------------------------------------------------------------#
# Define training control method; 10 - k - cross validation
train_control <- trainControl(method="cv", number=10)
# Train the model
model <- train(y~., data=data.train, trControl=train_control, method="pls")
# Find out what model is best
print(model)
# Find out most important variables
Varimportance = varImp(model)
cat(paste("Best model fit with", model$bestTune, "latent components \n"))
cat(paste("Latent components:",paste(rownames(Varimportance$importance)[order(decreasing = T,Varimportance$importance$Overall)][1:model$bestTune[1,]],collapse = ", "),"\n"))
plot(Varimportance, main="Varible importance in PLS model \n")
# Predict test set
ypredCARET.pls.test <- model %>% predict(data.test)
# Root mean squared error
RMSE.pls.test = RMSE(yactual.test, ypredCARET.pls.test)
RMSE.pls.test
# Results in: 16.09
# Mean absolute error
MAE.pls.test = MAE(yactual.test, ypredCARET.pls.test)
MAE.pls.test
# Results in: 14.97
# Plot ypred vs yactual of test data
plot(yactual.test, ypredCARET.pls.test,
xlab="Observed BP test set", ylab="Predicted BP test set",
pch=19, xlim=c(0, ceiling(max(yNN)*1.1)), ylim=c(0, ceiling(max(yNN)*1.1)),main="Prediction error test set (PLS model)")
abline(0,1, col='red')
text(200,ceiling(max(yNN)*1.1),paste("RMSE: ",RMSE.pls.test))
text(200,ceiling(max(yNN)*1.1)-50,paste("MAE: ",MAE.pls.test))
# Predict training data; check overfitting
ypredCARET.pls.train <- model %>% predict(data.train)
# Root mean squared error
RMSE.pls.train = RMSE(yactual.train, ypredCARET.pls.train)
RMSE.pls.train
# Results in: 19.94
# Mean absolute error
MAE.pls.train = MAE(yactual.train, ypredCARET.pls.train)
MAE.pls.train
# Results in: 14.84
# Plot ypred vs yactual of training data
plot(yactual.train, ypredCARET.pls.train,
xlab="Observed BP train set", ylab="Predicted BP train set",
pch=19, xlim=c(0, ceiling(max(yNN)*1.1)), ylim=c(0, ceiling(max(yNN)*1.1)),main="Prediction error training set (PLS model)")
abline(0,1, col='red')
text(200,ceiling(max(yNN)*1.1),paste("RMSE: ",RMSE.pls.train))
text(200,ceiling(max(yNN)*1.1)-50,paste("MAE: ",MAE.pls.train))
#-----------------------------------------------------------------------------------------------------#
#							CARET : RF
#-----------------------------------------------------------------------------------------------------#
# Define training control method; 10 - k - cross validation
train_control <- trainControl(method="cv", number=10)
# Train the model
model <- train(y~., data=data.train, trControl=train_control, method="rf")
# Find out what model is best
print(model)
# Find out most important variables - BLOCKED - this doesnt work for rf
if(F){
Varimportance = varImp(model)
cat(paste("Best model fit with", model$bestTune, "latent components \n"))
cat(paste("Latent components:",paste(rownames(Varimportance$importance)[order(decreasing = T,Varimportance$importance$Overall)][1:model$bestTune[1,]],collapse = ", "),"\n"))
plot(Varimportance, main="Varible importance in rf model \n")
}
# Predict test set
ypredCARET.rf.test <- model %>% predict(data.test)
# Root mean squared error
RMSE.rf.test = RMSE(yactual.test, ypredCARET.rf.test)
RMSE.rf.test
# Results in: 8.19
# Mean absolute error
MAE.rf.test = MAE(yactual.test, ypredCARET.rf.test)
MAE.rf.test
# Results in: 5.35
# Plot ypred vs yactual of test data
plot(yactual.test, ypredCARET.rf.test,
xlab="Observed BP test set", ylab="Predicted BP test set",
pch=19, xlim=c(0, ceiling(max(yNN)*1.1)), ylim=c(0, ceiling(max(yNN)*1.1)),main="Prediction error test set (RandomForest model)")
abline(0,1, col='red')
text(200,ceiling(max(yNN)*1.1),paste("RMSE: ",RMSE.rf.test))
text(200,ceiling(max(yNN)*1.1)-50,paste("MAE: ",MAE.rf.test))
# Predict training data; check overfitting
ypredCARET.rf.train <- model %>% predict(data.train)
# Root mean squared error
RMSE.rf.train = RMSE(yactual.train, ypredCARET.rf.train)
RMSE.rf.train
# Results in: 7.65
# Mean absolute error
MAE.rf.train = MAE(yactual.train, ypredCARET.rf.train)
MAE.rf.train
# Results in: 3.78
# Plot ypred vs yactual of training data
plot(yactual.train, ypredCARET.rf.train,
xlab="Observed BP train set", ylab="Predicted BP train set",
pch=19, xlim=c(0, ceiling(max(yNN)*1.1)), ylim=c(0, ceiling(max(yNN)*1.1)),main="Prediction error training set (RandomForest model)")
abline(0,1, col='red')
text(200,ceiling(max(yNN)*1.1),paste("RMSE: ",RMSE.rf.train))
text(200,ceiling(max(yNN)*1.1)-50,paste("MAE: ",MAE.rf.train))
motifsize = 4
g <- barabasi.game(n=15,directed = T)
#erdos.renyi.game # randomn
plot(g)
motifs(g, motifsize)
which(motifs(g, motifsize)>=1)
# create the motif MINUS ONE BECAUSE THESE FACKERS START AT 0; THIS IS R NOT FUCKING C++
#plot(graph.isocreate(size=3, number=3-1,directed = T))
graph = g
# Find network motifs in the graph "graph":
mygraphmotifs <- graph.motifs(graph, motifsize)
# Find which motifs occur:
for (i in 1:length(mygraphmotifs))
{
if(is.na(mygraphmotifs[i])){next}
motif <- mygraphmotifs[i]
if (motif > 0) # There are some occurrences of this motif
{
print(i)
# Find out what the motif looks like:
motifgraph <- graph.isocreate(size=motifsize, number=i-1, directed=TRUE)
edges <- E(motifgraph)
plot(motifgraph)
text(-1,-1,paste("This motif occurs",motif,"times."))
print(paste("This motif occurs",motif,"times:"))
print(edges)
}
}
library(igraph)
motifsize = 4
g <- barabasi.game(n=15,directed = T)
#erdos.renyi.game # randomn
plot(g)
motifs(g, motifsize)
which(motifs(g, motifsize)>=1)
# create the motif MINUS ONE BECAUSE THESE FACKERS START AT 0; THIS IS R NOT FUCKING C++
#plot(graph.isocreate(size=3, number=3-1,directed = T))
graph = g
# Find network motifs in the graph "graph":
mygraphmotifs <- graph.motifs(graph, motifsize)
# Find which motifs occur:
for (i in 1:length(mygraphmotifs))
{
if(is.na(mygraphmotifs[i])){next}
motif <- mygraphmotifs[i]
if (motif > 0) # There are some occurrences of this motif
{
print(i)
# Find out what the motif looks like:
motifgraph <- graph.isocreate(size=motifsize, number=i-1, directed=TRUE)
edges <- E(motifgraph)
plot(motifgraph)
text(-1,-1,paste("This motif occurs",motif,"times."))
print(paste("This motif occurs",motif,"times:"))
print(edges)
}
}
motifs(g, motifsize)
plot(graph.isocreate(size=3, number=3-1,directed = T))
plot(graph.isocreate(size=3, number=4,directed = T))
plot(graph.isocreate(size=4, number=4,directed = T))
plot(graph.isocreate(size=4, number=3,directed = T))
#-----------------------------------------------------------------------------------------------------#
#		Block 00		GENERAL INFORMATION
#-----------------------------------------------------------------------------------------------------#
# Copyright statement comment:
#   All rights reserved.
#
# Author comment:
#   Rick Reijnders
#   Script version: 11-10-2019
# File description:
#	Name
#	  Mainscript.R
#
rm(list=ls()) # clean workspace
#-----------------------------------------------------------------------------------------------------#
#		Block 01		(Install &) Load packages
#-----------------------------------------------------------------------------------------------------#
# Install packages if needed and load, or just load packages
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager", ask = F)
# Insert all packages in requiredpackages
requiredpackages <-
c("GRENITS",
"igraph",
"corrr",
"GENIE3",
"parmigene",
"RCy3")
for (i in requiredpackages) {
if (!requireNamespace(i, quietly = TRUE))
BiocManager::install(i, ask = F, dependencies = TRUE)
require(as.character(i), character.only = TRUE)
print(i)
}
#-----------------------------------------------------------------------------------------------------#
#		Block 02a		GENERAL Settings
#-----------------------------------------------------------------------------------------------------#
options(stringsAsFactors 	= F)
motifsize 					= 4
#-----------------------------------------------------------------------------------------------------#
#		Block 02b		INPUT Settings
#-----------------------------------------------------------------------------------------------------#
DataFolderLocation 		= "/Github/MSB1014-Network_Biology-Project/Project/Notebook/" 	# Must be in format "/location...DatalocationFolder/"
#-----------------------------------------------------------------------------------------------------#
#		Block 03		Prepare folders and load data
#-----------------------------------------------------------------------------------------------------#
# Data_dir should contain the data file!
if(Sys.info()[6]=="RR"){
data_dir <- paste("D:",DataFolderLocation,sep="")  # Rick's link (laptop)
}else if(Sys.info()[6]=="Admin"){
data_dir <- paste("D:/Games",DataFolderLocation,sep="")  # Rick's other link (desktop)
}
# Get folder and move to one level above, then make new folder containing timestamp
setwd(data_dir)
#-----------------------------------------------------------------------------------------------------#
#							Load data
#-----------------------------------------------------------------------------------------------------#
data <- read.delim("insilico-data.txt", row.names=1)
set.seed(1) # for reproducibility of results
#-----------------------------------------------------------------------------------------------------#
#							True network definition and analalysis
#-----------------------------------------------------------------------------------------------------#
graph.True = graph_from_literal(ErbB3.P--+Ras.GTP,ErbB3.P--+Gab1.P,ErbB3.P--+ErbB1.P,ErbB3.P--+PIP2,ErbB3.P--+SHC.P,ErbB3.P--+ErbB2.P,ErbB3.P--+PIP3,ERK.P.P--+ErbB3.P,ERK.P.P--+Gab1.P,ERK.P.P--+SOS.P,ERK.P.P--+ErbB1.P,ERK.P.P--+ErbB2.P,ERK.P.P--+ERK.P,Ras.GTP--+ErbB3.P,Ras.GTP--+ErbB1.P,Ras.GTP--+ErbB4.P,Ras.GTP--+SHC.P,Ras.GTP--+RAF.P,Ras.GTP--+ErbB2.P,MEK.P.P--+ERK.P.P,MEK.P.P--+MEK.P,MEK.P.P--+ERK.P,Gab1.P--+ErbB3.P,Gab1.P--+Ras.GTP,Gab1.P--+ErbB1.P,Gab1.P--+ErbB4.P,Gab1.P--+PIP2,Gab1.P--+ErbB2.P,Gab1.P--+PIP3,ErbB1.P--+ErbB3.P,ErbB1.P--+Ras.GTP,ErbB1.P--+Gab1.P,ErbB1.P--+SOS.P,ErbB1.P--+ErbB4.P,ErbB1.P--+PIP2,ErbB1.P--+SHC.P,ErbB1.P--+ErbB2.P,ErbB1.P--+PIP3,AKT.P--+AKT.P.P,ErbB4.P--+Ras.GTP,ErbB4.P--+Gab1.P,ErbB4.P--+ErbB1.P,ErbB4.P--+PIP2,ErbB4.P--+SHC.P,ErbB4.P--+ErbB2.P,ErbB4.P--+PIP3,PIP2--+Gab1.P,PIP2--+ErbB4.P,PIP2--+ErbB2.P,PIP2--+PIP3,MEK.P--+MEK.P.P,SHC.P--+ErbB3.P,SHC.P--+Ras.GTP,SHC.P--+SOS.P,SHC.P--+ErbB1.P,SHC.P--+ErbB4.P,SHC.P--+ErbB2.P,RAF.P--+Ras.GTP,RAF.P--+MEK.P.P,RAF.P--+MEK.P,ErbB2.P--+ErbB3.P,ErbB2.P--+Ras.GTP,ErbB2.P--+Gab1.P,ErbB2.P--+ErbB1.P,ErbB2.P--+ErbB4.P,ErbB2.P--+PIP2,ErbB2.P--+SHC.P,ErbB2.P--+PIP3,ERK.P--+ERK.P.P,PIP3--+AKT.P,PIP3--+PIP2,PIP3--+AKT.P.P,AKT.P.P--+AKT.P,AKT.P.P--+RAF.P)
#nodes:
V(graph.True)
length(V(graph.True))
#links:
E(graph.True)
length(E(graph.True))
#-----------------------------------------------------------------------------------------------------#
#		Script block 3: FUNCTIONS
#-----------------------------------------------------------------------------------------------------#
# Get motifs fromgraph and plot the motifs with frequency
GetMotifsFromGraph = function(graph.name, motifsize = 4, directed=TRUE, amountRandomNets = 1000, betaFactor = 1.3){
# motifsize = 4 # motif size
# directed = TRUE # directed
# amountRandomNets = 1000 # amount of random nets
# betaFactor = 1.3 # The probability distribution in 'amountRandomNets' networks is risen to the power of beta, to cut on significant motifs
graph = get(graph.name)
#if(exists("randomNetMotifsTotal")){rm(randomNetMotifsTotal)}
# Find network motifs in the graph "graph":
mygraphmotifs <- graph.motifs(graph, motifsize)
# Find which motifs occur:
for (i in 1:length(mygraphmotifs))
{
if(is.na(mygraphmotifs[i])){next}
motif <- mygraphmotifs[i]
if (motif > 0) # There are some occurrences of this motif
{
# print(i)
# Find out what the motif looks like:
motifgraph <- graph.isocreate(size=motifsize, number=i-1, directed=directed)
edges <- E(motifgraph)
plot(motifgraph)
text(-0.5,-1.2,paste("This motif(",i-1,") occurs ",motif," times:",sep=""))
print(paste("Motif",i-1,"occurs",motif,"times."))
#cat(edges)
}
}
print(mygraphmotifs)
mygraphmotifs[is.na(mygraphmotifs)]=0
# start statistical testing
graph = delete.vertices(graph, degree(graph)==0)
meanInDegree = mean(degree(graph,mode = "in"))
meanOutDegree = mean(degree(graph,mode = "out"))
# start random net generation; create distribution
for(p in 1:amountRandomNets){
g <- barabasi.game(n=length(V(graph)),directed = directed)
randomNetMotifs = graph.motifs(g, motifsize)
randomNetMotifs[is.na(randomNetMotifs)]=0
if(!exists("randomNetMotifsTotal")){
randomNetMotifsTotal = randomNetMotifs
}else{
randomNetMotifsTotal = randomNetMotifsTotal + randomNetMotifs
}
}
randomNetMotifsTotal = randomNetMotifsTotal/amountRandomNets
# Which occured more than random:
impMotifIndex = which(mygraphmotifs>(randomNetMotifsTotal^betaFactor))-1
if(length(impMotifIndex) == 0 ){
print("no significant motifs")
}else{
print(impMotifIndex)
# get locations
for(i in 1:length(impMotifIndex)){
pattern = graph.isocreate(size=motifsize, number=impMotifIndex[i], directed=directed)
iso <- subgraph_isomorphisms(pattern, graph)      # takes a while
motifsZ <- lapply(iso, function (x) { induced_subgraph(graph, x) })
for( p in 2:length(motifsZ)){
if(!exists("a")){a=motifsZ[[1]]}else{a=new_g}
b=motifsZ[[p]]
#V(a)$name <- V(a)$label
#V(b)$name <- V(b)$label
attrs <- rbind(as_data_frame(a, "vertices"), as_data_frame(b, "vertices")) %>% unique()
el <- rbind(as_data_frame(a), as_data_frame(b))
#@RRR check if this really is one motif
new_g <- graph_from_data_frame(el, directed = TRUE, vertices = attrs)
}
rm(a)
rm(b)
plot(new_g)
text(-0.5,-1.2,paste("Assembled network contains ",length(motifsZ)," motifs(",impMotifIndex[i],").",sep=""))
title("Complex")
plot(simplify(new_g))
text(-0.5,-1.2,paste("Assembled network contains ",length(motifsZ)," motifs(",impMotifIndex[i],").",sep=""))
title("Simplified")
# check below!...
if(!exists("endresult")){a=new_g}else{a=endresult}
b=new_g
#V(a)$name <- V(a)$label
#V(b)$name <- V(b)$label
attrs <- rbind(as_data_frame(a, "vertices"), as_data_frame(b, "vertices")) %>% unique()
el <- rbind(as_data_frame(a), as_data_frame(b))
endresult <- graph_from_data_frame(el, directed = TRUE, vertices = attrs)
rm(a)
rm(b)
}
plot((endresult))
plot(simplify(endresult))
# ...to this!
}
}
if(F){ # playground
# pattern = graph.isocreate(size=motifsize, number=3, directed=directed)
# iso <- subgraph_isomorphisms(pattern, graph)      # takes a while
# motifsZ <- lapply(iso, function (x) { induced_subgraph(graph, x) })
# isomorphic(motifsZ[[1]],motifsZ[[2]])
for( p in 2:length(motifsZ)){
if(!exists("a")){a=motifsZ[[1]]}else{a=new_g}
b=motifsZ[[p]]
#V(a)$name <- V(a)$label
#V(b)$name <- V(b)$label
attrs <- rbind(as_data_frame(a, "vertices"), as_data_frame(b, "vertices")) %>% unique()
el <- rbind(as_data_frame(a), as_data_frame(b))
new_g <- graph_from_data_frame(el, directed = TRUE, vertices = attrs)
}
plot(new_g)
plot(simplify(new_g))
}
#-----------------------------------------------------------------------------------------------------#
#							Bayesian networks
#-----------------------------------------------------------------------------------------------------#
# directed
# 20N 16L
#
output.folder <- paste(data_dir,"Bayes",sep="")
LinearNet(output.folder, data)
analyse.output(output.folder)
prob.file <- paste(output.folder, "/NetworkProbability_Matrix.txt", sep = "")
prob.mat <- read.table(prob.file)
prob.mat <- as.matrix(prob.mat)
threshold = 0.08
prob.mat[prob.mat < threshold] <- 0
graph.Bayes <- igraph::graph_from_adjacency_matrix(prob.mat,weighted=TRUE)
plot(graph.Bayes)
#nodes: 20
V(graph.Bayes)
length(V(graph.Bayes))
#links: 16
E(graph.Bayes)
length(E(graph.Bayes))
GetMotifsFromGraph("graph.Bayes")
#createNetworkFromIgraph(graph.Bayes, title="GRENITS",collection="Bayesian")
#copyVisualStyle("default","GRENITS")
#setVisualStyle("GRENITS")
#setEdgeTargetArrowShapeDefault("Arrow", style.name = "GRENITS")
